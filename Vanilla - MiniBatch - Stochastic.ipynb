{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HW \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "################################################  FUNCTIONS  ######################################\n",
    "\n",
    "###########  1- Vanila GD  ##########\n",
    "def LinearReg_GD (xdata,ydata,learn_rate,max_iter):\n",
    "    \n",
    "    #to make sure given data is numpy form\n",
    "    xdata = np.array(xdata)\n",
    "    ydata = np.array(ydata)\n",
    "    m = len(xdata)\n",
    "\n",
    "    #First Assumptions\n",
    "    theta0 = 0\n",
    "    theta1 = 0\n",
    "    #Learning Rate\n",
    "    alpha = learn_rate\n",
    "    \n",
    "\n",
    "\n",
    "    #Making Two arrays to plot the cost function of theta1\n",
    "    theta0Arr=[]\n",
    "    theta1Arr=[]\n",
    "    LossArr=[]\n",
    "    hArr=[]  \n",
    "    \n",
    "    for i in range (max_iter):\n",
    "        \n",
    "        #Hyp Func. [Predicted Output]\n",
    "        h0 = theta0 + theta1 * xdata #Predicted output\n",
    "        \n",
    "        #Loss\n",
    "        Loss = (1/(2*m))*np.sum((h0-y)**2)\n",
    "        \n",
    "        #Adding results to the arrays\n",
    "        LossArr.append(Loss)\n",
    "        theta1Arr.append(theta1)\n",
    "        theta0Arr.append(theta0)\n",
    "        hArr.append(h0)\n",
    "\n",
    "        #updating theta1\n",
    "        error1 = (h0-ydata)*xdata\n",
    "        theta1 = theta1 - (alpha/len(xdata))*np.sum(error1)\n",
    "\n",
    "        #updating theta0\n",
    "        error0 = h0-ydata\n",
    "        theta0 = theta0 - (alpha/len(xdata))*np.sum(error0)\n",
    "        \n",
    "        if Loss < 0.1 :\n",
    "            break;\n",
    "        \n",
    "        #End for Loop\n",
    "\n",
    "    #Return VALUES:\n",
    "    return theta0Arr , theta1Arr , LossArr , hArr , theta0 , theta1\n",
    "#############################################################################################################\n",
    "#############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########  2- MiniBatch GD  ##########\n",
    "## Batch Divider Function ##\n",
    "def MiniBatch_divider (InputArr,BatchSize):\n",
    "    i = 0\n",
    "    Batches = []\n",
    "    \n",
    "    while i < len(InputArr):\n",
    "        if i + BatchSize < len(InputArr):\n",
    "            B = InputArr[i:i + BatchSize]\n",
    "            Batches.append(B)\n",
    "        else:\n",
    "            B = InputArr[i:]\n",
    "            Batches.append(B)\n",
    "        \n",
    "        i = i + BatchSize\n",
    "    return Batches\n",
    "                            ##########################\n",
    "                            ##########################\n",
    "\n",
    "\n",
    "def MiniBatch_GD (xdata,ydata,learn_rate,epochs,batch_size):\n",
    "    \n",
    "    #to make sure given data is numpy form\n",
    "    xdata = np.array(xdata)\n",
    "    ydata = np.array(ydata)\n",
    "    m = len(xdata)\n",
    "\n",
    "    #First Assumptions\n",
    "    theta0 = 0\n",
    "    theta1 = 0\n",
    "    #Learning Rate\n",
    "    alpha = learn_rate\n",
    "    \n",
    "\n",
    "\n",
    "    #Making Two arrays to plot the cost function of theta1\n",
    "    theta0Arr=[]\n",
    "    theta1Arr=[]\n",
    "    LossArr=[]\n",
    "    hArr=[]\n",
    "   \n",
    "    for i in range (epochs):\n",
    "        \n",
    "        xBatches = MiniBatch_divider (xdata,batch_size)\n",
    "        yBatches = MiniBatch_divider (ydata,batch_size)\n",
    "        \n",
    "        for j in range(len(xBatches)):\n",
    "            \n",
    "            #Hyp Func. [Predicted Output] TOTAL Hyp\n",
    "            hTot = theta0 + theta1 * xdata #Predicted output\n",
    "\n",
    "            #Loss\n",
    "            Loss = (1/(2*m))*np.sum((hTot-y)**2)\n",
    "\n",
    "            #Adding results to the arrays\n",
    "            LossArr.append(Loss)\n",
    "            theta1Arr.append(theta1)\n",
    "            theta0Arr.append(theta0)\n",
    "            hArr.append(hTot)\n",
    "            \n",
    "            \n",
    "            #updating hyp for batch size\n",
    "            h0 = theta0 + theta1 * xBatches[j]\n",
    "\n",
    "            #updating theta1\n",
    "            error1 = (h0-yBatches[j])*xBatches[j]\n",
    "            theta1 = theta1 - (alpha/len(xBatches))*np.sum(error1)\n",
    "\n",
    "            #updating theta0\n",
    "            error0 = h0-yBatches[j]\n",
    "            theta0 = theta0 - (alpha/len(xBatches))*np.sum(error0)\n",
    "\n",
    "        #Stopping Criteria\n",
    "        if Loss < 0.1 :\n",
    "             break;\n",
    "\n",
    "            #End for Loop\n",
    "\n",
    "    #Return VALUES:\n",
    "    return theta0Arr , theta1Arr , LossArr , hArr , theta0 , theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "#############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###########  3-Stochastic GD  ##########\n",
    "def Stochastic_GD (xdata,ydata,learn_rate,epochs):\n",
    "    \n",
    "    #to make sure given data is numpy form\n",
    "    xdata = np.array(xdata)\n",
    "    ydata = np.array(ydata)\n",
    "    m = len(xdata)\n",
    "\n",
    "    #First Assumptions\n",
    "    theta0 = 0\n",
    "    theta1 = 0\n",
    "    #Learning Rate\n",
    "    alpha = learn_rate\n",
    "    \n",
    "\n",
    "\n",
    "    #Making Two arrays to plot the cost function of theta1\n",
    "    theta0Arr=[]\n",
    "    theta1Arr=[]\n",
    "    LossArr=[]\n",
    "    hArr=[]\n",
    "   \n",
    "    for i in range (epochs):\n",
    "        for j in range (len(xdata)):\n",
    "\n",
    "            #Hyp Func. [Predicted Output] TOTAL Hyp\n",
    "            h0 = theta0 + theta1 * xdata #Predicted output\n",
    "\n",
    "            #Loss\n",
    "            Loss = (1/(2*m))*np.sum((h0-y)**2)\n",
    "\n",
    "            #Adding results to the arrays\n",
    "            LossArr.append(Loss)\n",
    "            theta1Arr.append(theta1)\n",
    "            theta0Arr.append(theta0)\n",
    "            hArr.append(h0)\n",
    "\n",
    "            #updating theta1\n",
    "            error1 = (h0[j]-ydata[j])*xdata[j]\n",
    "            theta1 = theta1 - (alpha/len(xdata))*error1\n",
    "\n",
    "            #updating theta0\n",
    "            error0 = h0[j]-ydata[j]\n",
    "            theta0 = theta0 - (alpha/len(xdata))*error0\n",
    "\n",
    "        #Stopping Criteria\n",
    "        if Loss < 0.1 :\n",
    "             break;\n",
    "\n",
    "            #End for Loop\n",
    "\n",
    "    #Return VALUES:\n",
    "    return theta0Arr , theta1Arr , LossArr , hArr , theta0 , theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "x =np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "y =np.array([2,4,6,8,10,12,14,16,18,20])\n",
    "\n",
    "\n",
    "### Applying Vanilla GD ###\n",
    "theta0Arr , theta1Arr , LossArr , hArr , theta0 , theta1 = LinearReg_GD (x,y,0.01,1000)\n",
    "\n",
    "### Plot Loss vs Epochs\n",
    "plt.plot(LossArr)\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.show()\n",
    "\n",
    "### Plot Loss vs theta0\n",
    "plt.plot(theta0Arr,LossArr)\n",
    "plt.title('Loss vs theta0')\n",
    "plt.xlabel('theta0')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "### Plot Loss vs theta1\n",
    "plt.plot(theta1Arr,LossArr)\n",
    "plt.title('Loss vs theta1')\n",
    "plt.xlabel('theta1')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "### Plot All regression Lines\n",
    "for i in hArr:\n",
    "    plt.plot(x,i)\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "\n",
    "### R2 Score:\n",
    "print('The R2 Score:',r2_score(y,hArr[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "x =np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "y =np.array([2,4,6,8,10,12,14,16,18,20])\n",
    "\n",
    "\n",
    "### Applying MiniBatch GD ###\n",
    "theta0Arr , theta1Arr , LossArr , hArr , theta0 , theta1 = MiniBatch_GD (x,y,0.01,10,3)\n",
    "\n",
    "### Plot Loss vs Epochs\n",
    "plt.plot(LossArr)\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.show()\n",
    "\n",
    "### Plot Loss vs theta0\n",
    "plt.plot(theta0Arr,LossArr)\n",
    "plt.title('Loss vs theta0')\n",
    "plt.xlabel('theta0')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "### Plot Loss vs theta1\n",
    "plt.plot(theta1Arr,LossArr)\n",
    "plt.title('Loss vs theta1')\n",
    "plt.xlabel('theta1')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "### Plot All regression Lines\n",
    "for i in hArr:\n",
    "    plt.plot(x,i)\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "\n",
    "### Plot the final Regression Line\n",
    "plt.plot(x,hArr[-1])\n",
    "plt.scatter(x,y)\n",
    "plt.title('Final Result')\n",
    "plt.show()\n",
    "\n",
    "### R2 Score:\n",
    "print('The R2 Score:',r2_score(y,hArr[-1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "x =np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "y =np.array([2,4,6,8,10,12,14,16,18,20])\n",
    "\n",
    "\n",
    "\n",
    "### Applying Stochastic GD ###\n",
    "theta0Arr , theta1Arr , LossArr , hArr , theta0 , theta1 = Stochastic_GD (x,y,0.01,10)\n",
    "\n",
    "### Plot Loss vs Epochs\n",
    "plt.plot(LossArr)\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.show()\n",
    "\n",
    "### Plot Loss vs theta0\n",
    "plt.plot(theta0Arr,LossArr)\n",
    "plt.title('Loss vs theta0')\n",
    "plt.xlabel('theta0')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "### Plot Loss vs theta1\n",
    "plt.plot(theta1Arr,LossArr)\n",
    "plt.title('Loss vs theta1')\n",
    "plt.xlabel('theta1')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "### Plot All regression Lines\n",
    "for i in hArr:\n",
    "    plt.plot(x,i)\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "\n",
    "### Plot the final Regression Line\n",
    "plt.plot(x,hArr[-1])\n",
    "plt.scatter(x,y)\n",
    "plt.title('Final Result')\n",
    "plt.show()\n",
    "\n",
    "### R2 Score:\n",
    "print('The R2 Score:',r2_score(y,hArr[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
